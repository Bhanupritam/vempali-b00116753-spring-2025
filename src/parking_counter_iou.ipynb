{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2191187,"sourceType":"datasetVersion","datasetId":1315526},{"sourceId":11549835,"sourceType":"datasetVersion","datasetId":7243013},{"sourceId":11551028,"sourceType":"datasetVersion","datasetId":7243661},{"sourceId":355816,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":296756,"modelId":317359}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pycocotools\n!pip install torchmetrics\n!pip install faster-coco-eval","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:35.474382Z","iopub.execute_input":"2025-04-24T18:40:35.474980Z","iopub.status.idle":"2025-04-24T18:40:44.307233Z","shell.execute_reply.started":"2025-04-24T18:40:35.474957Z","shell.execute_reply":"2025-04-24T18:40:44.306507Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\nRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.7.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (1.26.4)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pycocotools) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pycocotools) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pycocotools) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pycocotools) (2024.2.0)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (1.7.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.5.1+cu124)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (0.14.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.1.0)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics) (2024.2.0)\nRequirement already satisfied: faster-coco-eval in /usr/local/lib/python3.11/dist-packages (1.6.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from faster-coco-eval) (1.26.4)\nRequirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from faster-coco-eval) (5.24.1)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from faster-coco-eval) (2.2.3)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from faster-coco-eval) (11.1.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->faster-coco-eval) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->faster-coco-eval) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->faster-coco-eval) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->faster-coco-eval) (2025.2)\nRequirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->faster-coco-eval) (9.0.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly->faster-coco-eval) (24.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->faster-coco-eval) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->faster-coco-eval) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->faster-coco-eval) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->faster-coco-eval) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->faster-coco-eval) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->faster-coco-eval) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json \nfrom tqdm import tqdm \nfrom pprint import pprint \nimport os\nimport matplotlib.pyplot as plt\nimport glob\nimport shutil\nimport cv2\nfrom PIL import Image\nimport torch\nimport torchvision\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision.transforms import ToTensor, Compose, Normalize, RandomAffine, ColorJitter\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nfrom torchmetrics.detection.mean_ap import MeanAveragePrecision","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:50.214946Z","iopub.execute_input":"2025-04-24T18:40:50.215568Z","iopub.status.idle":"2025-04-24T18:40:54.968705Z","shell.execute_reply.started":"2025-04-24T18:40:50.215539Z","shell.execute_reply":"2025-04-24T18:40:54.967933Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"dataset_path = \"/kaggle/input/pklot-dataset\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:57.503738Z","iopub.execute_input":"2025-04-24T18:40:57.504214Z","iopub.status.idle":"2025-04-24T18:40:57.507975Z","shell.execute_reply.started":"2025-04-24T18:40:57.504188Z","shell.execute_reply":"2025-04-24T18:40:57.507131Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:58.242095Z","iopub.execute_input":"2025-04-24T18:40:58.242385Z","iopub.status.idle":"2025-04-24T18:40:58.280535Z","shell.execute_reply.started":"2025-04-24T18:40:58.242365Z","shell.execute_reply":"2025-04-24T18:40:58.279905Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_dir = '/kaggle/input/pklot-dataset/train'\ntest_dir = '/kaggle/input/pklot-dataset/test'\nval_dir = '/kaggle/input/pklot-dataset/valid'\noutput_path = \"/kaggle/working/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:58.938538Z","iopub.execute_input":"2025-04-24T18:40:58.938819Z","iopub.status.idle":"2025-04-24T18:40:58.942670Z","shell.execute_reply.started":"2025-04-24T18:40:58.938797Z","shell.execute_reply":"2025-04-24T18:40:58.942012Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def get_json_file(directory):\n    json_files = glob.glob(os.path.join(directory, \"**\", \"*.json\"), recursive = True)\n    return str(json_files[0]) if json_files else None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:40:59.584668Z","iopub.execute_input":"2025-04-24T18:40:59.585415Z","iopub.status.idle":"2025-04-24T18:40:59.589198Z","shell.execute_reply.started":"2025-04-24T18:40:59.585388Z","shell.execute_reply":"2025-04-24T18:40:59.588418Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"anno_train = get_json_file(train_dir)\nanno_val = get_json_file(val_dir)\nanno_test = get_json_file(test_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:41:01.226400Z","iopub.execute_input":"2025-04-24T18:41:01.226700Z","iopub.status.idle":"2025-04-24T18:41:10.256077Z","shell.execute_reply.started":"2025-04-24T18:41:01.226671Z","shell.execute_reply":"2025-04-24T18:41:10.255475Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"with open(anno_train, \"r\") as file:\n    data = json.load(file)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:41:10.257209Z","iopub.execute_input":"2025-04-24T18:41:10.257478Z","iopub.status.idle":"2025-04-24T18:41:13.259377Z","shell.execute_reply.started":"2025-04-24T18:41:10.257445Z","shell.execute_reply":"2025-04-24T18:41:13.258742Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"data['categories']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:51:27.537841Z","iopub.execute_input":"2025-04-24T16:51:27.538052Z","iopub.status.idle":"2025-04-24T16:51:27.543210Z","shell.execute_reply.started":"2025-04-24T16:51:27.538035Z","shell.execute_reply":"2025-04-24T16:51:27.542515Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"[{'id': 0, 'name': 'spaces', 'supercategory': 'none'},\n {'id': 1, 'name': 'space-empty', 'supercategory': 'spaces'},\n {'id': 2, 'name': 'space-occupied', 'supercategory': 'spaces'}]"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, img_dir, ann_file, transforms=None):\n        self.img_dir = img_dir\n        self.transforms = transforms\n\n        with open(ann_file, 'r') as f:\n            coco = json.load(f)\n\n        self.images = coco['images']\n        self.annotations = coco['annotations']\n        self.categories = coco['categories']\n\n        self.image_to_annotations = {}\n        for ann in self.annotations:\n            img_id = ann['image_id']\n            if img_id not in self.image_to_annotations:\n                self.image_to_annotations[img_id] = []\n            self.image_to_annotations[img_id].append(ann)\n\n        self.images = [\n            img for img in self.images\n            if img['id'] in self.image_to_annotations and\n               len(self.image_to_annotations[img['id']]) > 0\n        ]\n\n    def __getitem__(self, idx):\n        img_info = self.images[idx]\n        img_id = img_info['id']\n        img_path = os.path.join(self.img_dir, img_info['file_name'])\n        img = Image.open(img_path).convert(\"RGB\")\n\n        annotations = self.image_to_annotations[img_id]\n\n        boxes = []\n        labels = []\n\n        for ann in annotations:\n            boxes.append(ann['bbox'])\n            labels.append(ann['category_id'])\n\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        boxes[:, 2:] += boxes[:, :2]  \n        labels = torch.as_tensor(labels, dtype=torch.int64)\n\n        target = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"image_id\": torch.tensor([img_id], dtype=torch.int64)  \n            }\n\n\n        if self.transforms:\n            img = self.transforms(img)\n\n        return img, target\n\n    def __len__(self):\n        return len(self.images)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:41:57.180624Z","iopub.execute_input":"2025-04-24T18:41:57.181201Z","iopub.status.idle":"2025-04-24T18:41:57.190170Z","shell.execute_reply.started":"2025-04-24T18:41:57.181169Z","shell.execute_reply":"2025-04-24T18:41:57.189404Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_transform = Compose([\n    RandomAffine(\n        degrees=(-5, 5),\n        translate=(0.15, 0.15),\n        scale=(0.85, 1.15),\n        shear=10\n    ),\n    ColorJitter(\n        brightness=0.125,\n        contrast=0.5,\n        saturation=0.5,\n        hue=0.05\n    ),\n    ToTensor(), \n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:41:57.982533Z","iopub.execute_input":"2025-04-24T18:41:57.982801Z","iopub.status.idle":"2025-04-24T18:41:57.987511Z","shell.execute_reply.started":"2025-04-24T18:41:57.982781Z","shell.execute_reply":"2025-04-24T18:41:57.986693Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"val_transform = (ToTensor())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:00.252688Z","iopub.execute_input":"2025-04-24T18:42:00.253404Z","iopub.status.idle":"2025-04-24T18:42:00.256768Z","shell.execute_reply.started":"2025-04-24T18:42:00.253378Z","shell.execute_reply":"2025-04-24T18:42:00.256037Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_dataset = CustomDataset(train_dir, anno_train, train_transform)\nval_dataset = CustomDataset(test_dir, anno_test, val_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:01.562656Z","iopub.execute_input":"2025-04-24T18:42:01.563225Z","iopub.status.idle":"2025-04-24T18:42:04.642763Z","shell.execute_reply.started":"2025-04-24T18:42:01.563204Z","shell.execute_reply":"2025-04-24T18:42:04.642154Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def collate_fn(batch):\n    batch = [item for item in batch if item is not None]\n    if not batch:  \n        return None, None\n    image, labels = zip(*batch)\n    return list(image), list(labels) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:04.643996Z","iopub.execute_input":"2025-04-24T18:42:04.644377Z","iopub.status.idle":"2025-04-24T18:42:04.648370Z","shell.execute_reply.started":"2025-04-24T18:42:04.644349Z","shell.execute_reply":"2025-04-24T18:42:04.647809Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"train_dataloader = DataLoader(\n    train_dataset,\n    batch_size=8,\n    shuffle=True,\n    collate_fn=  collate_fn\n)\n\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=8,\n    shuffle=False,\n    collate_fn= collate_fn\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:04.649161Z","iopub.execute_input":"2025-04-24T18:42:04.649406Z","iopub.status.idle":"2025-04-24T18:42:04.662338Z","shell.execute_reply.started":"2025-04-24T18:42:04.649385Z","shell.execute_reply":"2025-04-24T18:42:04.661799Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def calculate_iou(box1, box2):\n    x1 = max(box1[0], box2[0])\n    y1 = max(box1[1], box2[1])\n    x2 = min(box1[2], box2[2])\n    y2 = min(box1[3], box2[3])\n\n    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n    area_box1 = (box1[2] - box1[0]) * (box1[3] - box1[1])\n    area_box2 = (box2[2] - box2[0]) * (box2[3] - box2[1])\n    union = area_box1 + area_box2 - intersection\n\n    return intersection / union if union != 0 else 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:04.663636Z","iopub.execute_input":"2025-04-24T18:42:04.663881Z","iopub.status.idle":"2025-04-24T18:42:04.675963Z","shell.execute_reply.started":"2025-04-24T18:42:04.663858Z","shell.execute_reply":"2025-04-24T18:42:04.675416Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"\ndef precision_recall(pred_boxes, gt_boxes, iou_threshold=0.5):\n    tp, fp, fn = 0, 0, 0\n    gt_matched = set()\n\n    for pred_box in pred_boxes:\n        matched = False\n        for i, gt_box in enumerate(gt_boxes):\n            if i in gt_matched:\n                continue\n            if calculate_iou(pred_box, gt_box) >= iou_threshold:\n                tp += 1\n                gt_matched.add(i)\n                matched = True\n                break\n        if not matched:\n            fp += 1\n\n    fn = len(gt_boxes) - len(gt_matched)\n    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n\n    return precision, recall","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:06.364712Z","iopub.execute_input":"2025-04-24T18:42:06.365304Z","iopub.status.idle":"2025-04-24T18:42:06.370250Z","shell.execute_reply.started":"2025-04-24T18:42:06.365282Z","shell.execute_reply":"2025-04-24T18:42:06.369467Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"num_classes = len(train_dataset.categories)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:07.920601Z","iopub.execute_input":"2025-04-24T18:42:07.921334Z","iopub.status.idle":"2025-04-24T18:42:07.924861Z","shell.execute_reply.started":"2025-04-24T18:42:07.921310Z","shell.execute_reply":"2025-04-24T18:42:07.923995Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"def get_model(num_classes):\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    \n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:08.536607Z","iopub.execute_input":"2025-04-24T18:42:08.537264Z","iopub.status.idle":"2025-04-24T18:42:08.542009Z","shell.execute_reply.started":"2025-04-24T18:42:08.537233Z","shell.execute_reply":"2025-04-24T18:42:08.540953Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"check_point_folder = os.path.join(output_path, \"check_point\")\nos.makedirs(check_point_folder, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:10.322759Z","iopub.execute_input":"2025-04-24T18:42:10.323424Z","iopub.status.idle":"2025-04-24T18:42:10.327885Z","shell.execute_reply.started":"2025-04-24T18:42:10.323391Z","shell.execute_reply":"2025-04-24T18:42:10.327182Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"num_epochs = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:10.782767Z","iopub.execute_input":"2025-04-24T18:42:10.783039Z","iopub.status.idle":"2025-04-24T18:42:10.786861Z","shell.execute_reply.started":"2025-04-24T18:42:10.783020Z","shell.execute_reply":"2025-04-24T18:42:10.785932Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"def train():\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    model = get_model(num_classes)\n    model.to(device)\n    optimizer = torch.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n    best_map = -1\n    metric = MeanAveragePrecision(iou_type=\"bbox\").to(device)\n    \n    check_point_folder = \"checkpoints\"\n    if not os.path.exists(check_point_folder):\n        os.makedirs(check_point_folder)\n\n    for epoch in range(num_epochs):\n        model.train()\n        train_loss = []\n        progress_bar = tqdm(train_dataloader, colour=\"cyan\")\n\n        for iter, (images, targets) in enumerate(progress_bar):\n            images = [image.to(device) for image in images]\n            targets = [{\"boxes\": target[\"boxes\"].to(device), \"labels\": target[\"labels\"].to(device)} for target in targets]\n\n            losses = model(images, targets)\n            loss = sum([loss for loss in losses.values()])\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            train_loss.append(loss.item())\n            mean_loss = sum(train_loss) / len(train_loss)\n            progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}. Loss {mean_loss:.4f}\")\n\n        # Evaluation phase\n        model.eval()\n        metric.reset()\n\n        precision_list, recall_list = [], []\n\n        with torch.no_grad():\n            for images, targets in val_dataloader:\n                images = [img.to(device) for img in images]\n                targets = [\n                    {\"boxes\": target[\"boxes\"].to(device), \"labels\": target[\"labels\"].to(device)}\n                    for target in targets\n                ]\n                outputs = model(images)\n\n                preds = [\n                    {\n                        \"boxes\": output[\"boxes\"].to(\"cpu\"),\n                        \"scores\": output[\"scores\"].to(\"cpu\"),\n                        \"labels\": output[\"labels\"].to(\"cpu\"),\n                    }\n                    for output in outputs\n                ]\n                gts = [\n                    {\n                        \"boxes\": target[\"boxes\"].to(\"cpu\"),\n                        \"labels\": target[\"labels\"].to(\"cpu\"),\n                    }\n                    for target in targets\n                ]\n\n                # Update metric for mAP\n                metric.update(preds, gts)\n\n                # Calculate precision and recall using your function\n                for pred, gt in zip(preds, gts):\n                    precision, recall = precision_recall(pred[\"boxes\"], gt[\"boxes\"], iou_threshold=0.5)\n                    precision_list.append(precision)\n                    recall_list.append(recall)\n\n        # Compute average precision and recall\n        avg_precision = sum(precision_list) / len(precision_list) if precision_list else 0\n        avg_recall = sum(recall_list) / len(recall_list) if recall_list else 0\n\n        # Compute mAP\n        result = metric.compute()\n        map_50 = result[\"map_50\"].item()\n        map_50_95 = result[\"map\"].item()  \n\n        print(f\"Epoch {epoch+1}/{num_epochs} - mAP@0.5: {map_50:.4f} - mAP@0.5:0.95: {map_50_95:.4f}, Precision: {avg_precision:.4f}, Recall: {avg_recall:.4f}\")\n\n\n        checkpoint = {\n            \"model_state_dict\": model.state_dict(),\n            \"epoch\": epoch + 1,\n            \"optimizer_state_dict\": optimizer.state_dict(),\n            \"map\": map_50\n        }\n\n        if map_50_95 > best_map:\n            best_map = map_50_95\n            torch.save(checkpoint, f\"{check_point_folder}/best.pt\")\n\n        torch.save(checkpoint, f\"{check_point_folder}/last.pt\")\n        torch.save(model.state_dict(), f\"{check_point_folder}/last_model.pth\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:11.310975Z","iopub.execute_input":"2025-04-24T18:42:11.311563Z","iopub.status.idle":"2025-04-24T18:42:11.326222Z","shell.execute_reply.started":"2025-04-24T18:42:11.311538Z","shell.execute_reply":"2025-04-24T18:42:11.325365Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"pip install torchmetrics[detection]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T18:42:14.631682Z","iopub.execute_input":"2025-04-24T18:42:14.631933Z","iopub.status.idle":"2025-04-24T18:42:17.710569Z","shell.execute_reply.started":"2025-04-24T18:42:14.631916Z","shell.execute_reply":"2025-04-24T18:42:17.709628Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchmetrics[detection] in /usr/local/lib/python3.11/dist-packages (1.7.1)\nRequirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (1.26.4)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (24.2)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (2.5.1+cu124)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (0.14.3)\nRequirement already satisfied: torchvision>=0.15.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (0.20.1+cu124)\nRequirement already satisfied: pycocotools>2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics[detection]) (2.0.8)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (75.1.0)\nRequirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics[detection]) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>1.20.0->torchmetrics[detection]) (2.4.1)\nRequirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools>2.0.0->torchmetrics[detection]) (3.7.5)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics[detection]) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics[detection]) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.15.1->torchmetrics[detection]) (11.1.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.4.8)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (3.2.1)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics[detection]) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics[detection]) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>1.20.0->torchmetrics[detection]) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>1.20.0->torchmetrics[detection]) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>1.20.0->torchmetrics[detection]) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>1.20.0->torchmetrics[detection]) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools>2.0.0->torchmetrics[detection]) (1.17.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T16:53:46.002330Z","iopub.execute_input":"2025-04-24T16:53:46.002628Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:00<00:00, 199MB/s] \nEpoch 1/10. Loss 1.5016: 100%|\u001b[36m██████████\u001b[0m| 1063/1063 [20:36<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10 - mAP@0.5: 0.0441 - mAP@0.5:0.95: 0.0111, Precision: 0.1410, Recall: 0.3325\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/10. Loss 1.3768: 100%|\u001b[36m██████████\u001b[0m| 1063/1063 [20:15<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2/10 - mAP@0.5: 0.0687 - mAP@0.5:0.95: 0.0231, Precision: 0.1692, Recall: 0.3808\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3/10. Loss 1.3292: 100%|\u001b[36m██████████\u001b[0m| 1063/1063 [20:18<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3/10 - mAP@0.5: 0.1041 - mAP@0.5:0.95: 0.0419, Precision: 0.1942, Recall: 0.4313\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4/10. Loss 1.3050:   5%|\u001b[36m▍         \u001b[0m| 50/1063 [00:57<19:27,  1.15s/it]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import cv2\nimport pickle\nimport torch\nfrom torchvision.transforms.functional import to_tensor\nfrom shapely.geometry import box as shapely_box\n\nslot_width = 130\nslot_height = 65\npad_x, pad_y = 3, 3              # More generous padding\nios_thresh = 0.05                  # Allow low IoU but still call it occupied\nscore_thresh = 0.35                # Keep low-confidence cars\ntarget_size = (1280, 720)  # match the size used in carposition.pkl collection\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:38:40.900269Z","iopub.execute_input":"2025-04-24T20:38:40.900548Z","iopub.status.idle":"2025-04-24T20:38:40.905278Z","shell.execute_reply.started":"2025-04-24T20:38:40.900529Z","shell.execute_reply":"2025-04-24T20:38:40.904506Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"# ==== LOAD MODEL ====\ndef get_model(num_classes):\n    from torchvision.models.detection import fasterrcnn_resnet50_fpn\n    from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n\n    model = fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    return model\n\ndef load_trained_model(checkpoint_path, num_classes):\n    model = get_model(num_classes)\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    model.to(device)\n    model.eval()\n    return model\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:38:41.484578Z","iopub.execute_input":"2025-04-24T20:38:41.485087Z","iopub.status.idle":"2025-04-24T20:38:41.489885Z","shell.execute_reply.started":"2025-04-24T20:38:41.485048Z","shell.execute_reply":"2025-04-24T20:38:41.489243Z"}},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# ==== LOAD PARKING SLOT POSITIONS ====\nwith open(\"/kaggle/input/positions/carposition.pkl\", \"rb\") as f:\n    top_left_coords = pickle.load(f)\n\nslot_boxes = [[x - pad_x, y - pad_y, x + slot_width + pad_x, y + slot_height + pad_y] for x, y in top_left_coords]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:38:43.858617Z","iopub.execute_input":"2025-04-24T20:38:43.859335Z","iopub.status.idle":"2025-04-24T20:38:43.864527Z","shell.execute_reply.started":"2025-04-24T20:38:43.859310Z","shell.execute_reply":"2025-04-24T20:38:43.863954Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"# ==== IoSA Function ====\ndef calculate_ios(slot_box, pred_box):\n    slot = shapely_box(*slot_box)\n    pred = shapely_box(*pred_box)\n    inter_area = slot.intersection(pred).area\n    slot_area = slot.area\n    return inter_area / slot_area if slot_area != 0 else 0\n\n\n# ==== PREDICTION LOOP ====\ndef predict_on_video_with_ios(video_path, output_path, model, slot_boxes,\n                              threshold=score_thresh, ios_thresh=ios_thresh):\n    cap = cv2.VideoCapture(video_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    out_vid = cv2.VideoWriter(output_path, cv2.VideoWriter_fourcc(*'mp4v'), fps, target_size)\n\n    print(\"🔄 Processing video with IoSA logic...\")\n\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n\n        frame = cv2.resize(frame, target_size)\n        frame_tensor = to_tensor(frame).unsqueeze(0).to(device)\n\n        with torch.no_grad():\n            outputs = model(frame_tensor)[0]\n\n        pred_boxes = outputs[\"boxes\"].cpu().numpy()\n        scores = outputs[\"scores\"].cpu().numpy()\n        pred_boxes = [box for box, score in zip(pred_boxes, scores) if score >= threshold]\n\n        free_count = 0\n\n        for i, slot in enumerate(slot_boxes):\n            is_occupied = any(calculate_ios(slot, pred_box) > ios_thresh for pred_box in pred_boxes)\n\n            x1, y1, x2, y2 = map(int, slot)\n            color = (0, 0, 255) if is_occupied else (0, 255, 0)\n            label = \"Occupied\" if is_occupied else \"Empty\"\n            text_color = (255, 255, 255) if is_occupied else (0, 0, 0)\n\n            if not is_occupied:\n                free_count += 1\n\n            # Draw slot box\n            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n            cv2.putText(frame, f\"{label}\", (x1 + 2, y1 + 15),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, text_color, 1)\n            cv2.putText(frame, f\"{i+1}\", (x1 + 3, y1 + 35),\n                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n\n        # Free space counter\n        cv2.putText(frame, f\"Free Spaces: {free_count}/{len(slot_boxes)}\",\n                    (40, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 255), 2)\n\n        out_vid.write(frame)\n\n    cap.release()\n    out_vid.release()\n    print(\"✅ Saved IoSA-based output to:\", output_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:38:45.829554Z","iopub.execute_input":"2025-04-24T20:38:45.830392Z","iopub.status.idle":"2025-04-24T20:38:45.839796Z","shell.execute_reply.started":"2025-04-24T20:38:45.830364Z","shell.execute_reply":"2025-04-24T20:38:45.839165Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"# ==== RUN EVERYTHING ====\ncheckpoint_path = \"/kaggle/input/best/other/default/1/best.pt\"\nvideo_path = \"/kaggle/input/parking-video/car_test.mp4\"\noutput_path = \"/kaggle/working/parking_final_fixed.mp4\"\n\nnum_classes = 3  # 0: spaces, 1: empty, 2: occupied (as per your dataset)\nmodel = load_trained_model(checkpoint_path, num_classes)\n\npredict_on_video_with_slots_only(video_path, output_path, model, slot_boxes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-24T20:38:48.317301Z","iopub.execute_input":"2025-04-24T20:38:48.318016Z","iopub.status.idle":"2025-04-24T20:47:13.814498Z","shell.execute_reply.started":"2025-04-24T20:38:48.317994Z","shell.execute_reply":"2025-04-24T20:47:13.813858Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_196/2659912271.py:13: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=device)\n","output_type":"stream"},{"name":"stdout","text":"🔄 Processing video...\n✅ Saved final video to: /kaggle/working/parking_final_fixed.mp4\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}